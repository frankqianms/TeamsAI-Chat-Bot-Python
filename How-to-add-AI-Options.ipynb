{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, you will learn to add AI options to a basic Teams-ai bot.\n",
    "\n",
    "A Teams-ai application object can have an `ApplicationOptions.ai` property with `AIOption` type. A bot application with `ApplicationOptions.ai` property can work as a bot with AI abilities. For example, it can give a artificial response to your input according to prompts.\n",
    "\n",
    "`AIOptions` consists of `planner`, `prompt` and `history`. The `prompt` determines what prompts to use. The `planner` will generate plan according to given prompts and chat history. We will show you how `prompt` and  `planner` work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt\n",
    "In most cases, you'll want to create your prompts in a separate file so you can easily import them into Teams-ai across multiple projects and share them with others. \n",
    "\n",
    "In this section, we'll demonstrate how to create the files necessary for a prompt so you can easily use them in `AIOption`.\n",
    "\n",
    "Here is a sample code snippet about how to generate a prompts home folder `src/prompts`, and a named prompt folder `src/prompts/chat`. In this example, the prompt will be called `'chat'`. Once inside of a prompts folder, you'll need to create two new files `config.json` and `skprompt.txt`. The `skprompt.txt` file contains the prompt that will be sent to the AI service and the `config.json` file contains the configuration along with semantic descriptions that can be used by planners.\n",
    "```\n",
    "Prompts\n",
    "│\n",
    "└─── chat\n",
    "     |\n",
    "     └─── config.json\n",
    "     └─── skprompt.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> In a real scenario, you wouldn't need to run the code bellow, but would need to manually manage the prompts folder following the file naming conventions. Please refer [semantic kernel doc](https://learn.microsoft.com/en-us/semantic-kernel/prompts/saving-prompts-as-files?tabs=python) for more information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Define the file paths\n",
    "prompts_home_folder_path = \"src/prompts/\"\n",
    "prompt_name_folder_path = \"chat/\"\n",
    "config_file_path = f\"{prompts_home_folder_path}{prompt_name_folder_path}config.json\"\n",
    "skprompt_file_path = f\"{prompts_home_folder_path}{prompt_name_folder_path}skprompt.txt\"\n",
    "if not os.path.exists(prompts_home_folder_path):\n",
    "    os.makedirs(prompts_home_folder_path)\n",
    "if not os.path.exists(f\"{prompts_home_folder_path}{prompt_name_folder_path}\"):\n",
    "    os.makedirs(f\"{prompts_home_folder_path}{prompt_name_folder_path}\")\n",
    "\n",
    "# Define the config_json and skprompt_txt\n",
    "config_json = \"\"\"{\n",
    "    \"schema\": 1,\n",
    "    \"description\": \"Chat with Teams Chef\",\n",
    "    \"type\": \"completion\",\n",
    "    \"completion\": {\n",
    "      \"max_tokens\": 150,\n",
    "      \"temperature\": 0.9,\n",
    "      \"top_p\": 0.0,\n",
    "      \"presence_penalty\": 0.6,\n",
    "      \"frequency_penalty\": 0.0,\n",
    "      \"stop_sequences\": [\n",
    "        \"Human:\",\n",
    "        \"AI:\"\n",
    "      ]\n",
    "    }\n",
    "}\"\"\"\n",
    "\n",
    "skprompt_txt = \"\"\"The following is a conversation with an AI assistant, its name is Teams Chef. \n",
    "Teams Chef is an expert in Microsoft Teams apps development and the Human is junior developer learning Microsoft Teams development for the first time. \n",
    "Teams Chef should always reply by explaining new concepts in simple terms using cooking as parallel concepts. \n",
    "Teams Chef should always greet the human, ask them their name, and then guide the junior developer in his journey to build new apps for Microsoft Teams.\n",
    "\n",
    "{{$history}}\n",
    "Human: {{$input}}\n",
    "TeamsChef:\"\"\"\n",
    "\n",
    "# Write the config_json to config.json file\n",
    "with open(config_file_path, \"w\") as config_file:\n",
    "    config_file.write(config_json)\n",
    "\n",
    "# Write the skprompt_txt to skprompt.txt file\n",
    "with open(skprompt_file_path, \"w\") as skprompt_file:\n",
    "    skprompt_file.write(skprompt_txt)\n",
    "\n",
    "# Print a success message\n",
    "print(f\"Files written successfully. Please check the files in the following paths:\\n{config_file_path}\\n{skprompt_file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Planner\n",
    "In this section, we will introduce how does a `planner` generates a plan."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. First, we import needed packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules from src\n",
    "import src.config as config\n",
    "from src.bot import *\n",
    "from teams import AIHistoryOptions, AzureOpenAIPlanner, AzureOpenAIPlannerOptions, ConversationHistory, ConversationState, TempState, UserState\n",
    "from botbuilder.schema import ChannelAccount, ConversationAccount\n",
    "from unittest.mock import MagicMock "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Second, we initiate a `planner` object with Azure OpenAI keys and values, determining prompt home folder.\n",
    "\n",
    "    > Please config your **AZURE_OPENAI_KEY**, **AZURE_OPENAI_MODEL_DEPLOYMENT_NAME** and **AZURE_OPENAI_ENDPOINT** in `.env` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# register a planner\n",
    "planner = AzureOpenAIPlanner(\n",
    "    AzureOpenAIPlannerOptions(\n",
    "        config.AZURE_OPENAI_KEY,\n",
    "        config.AZURE_OPENAI_MODEL_DEPLOYMENT_NAME,\n",
    "        config.AZURE_OPENAI_ENDPOINT,\n",
    "        prompt_folder=\"src/prompts\",\n",
    "    )\n",
    ")\n",
    "print(f\"AZURE_OPENAI_KEY={config.AZURE_OPENAI_KEY}\")\n",
    "print(f\"AZURE_OPENAI_MODEL_DEPLOYMENT_NAME={config.AZURE_OPENAI_MODEL_DEPLOYMENT_NAME}\")\n",
    "print(f\"AZURE_OPENAI_ENDPOINT={config.AZURE_OPENAI_ENDPOINT}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Then, we mock a `TurnContext` object and a `TurnState` object. They will be used when generating a plan. We already defined them in [src/utils/mockConstants.py](src/utils/mockConstants.py).\n",
    "\n",
    "    > In this example, we set `TempState.input='hi'` to emulate that user inputs 'hi' as the input text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.mockConstants import *\n",
    "\n",
    "print(f\"context={context}\")\n",
    "print(f\"state.temp={state.temp}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Last, we call `planner._prompt_manager.render_prompt()` and `planner.generate_plan()` to see what prompt content passed to planner and what plan is generated by planner. \n",
    "\n",
    "    > In this example, we choose `\"chat\"` as the prompt template name to generate a prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# render prompt\n",
    "prompt_name=\"chat\"\n",
    "prompt = await planner._prompt_manager.render_prompt(context, state, prompt_name)\n",
    "print(f\"prompt:\\n{prompt.text}\\n\")\n",
    "\n",
    "# generate plan\n",
    "plan = await planner.generate_plan(\n",
    "    context, state, prompt_name, history_options=AIHistoryOptions(assistant_history_type=\"text\")\n",
    ")\n",
    "print(f\"plan:\\n{plan}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add AIOptions to a bot\n",
    "Now we know how to manage the prompts folder and how to set up a planner. We can initiate a Teams-ai bot application with `AIOptions` with `prompt` and `planner` we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from botbuilder.core import BotFrameworkAdapterSettings, MemoryStorage\n",
    "from teams import AIOptions, Application, ApplicationOptions, TurnState\n",
    "storage = MemoryStorage()\n",
    "app = Application[TurnState](\n",
    "    ApplicationOptions(\n",
    "        auth=BotFrameworkAdapterSettings(\n",
    "            app_id=config.app_id,\n",
    "            app_password=config.app_password,\n",
    "        ),\n",
    "        ai=AIOptions(\n",
    "            planner=planner,\n",
    "            prompt=\"chat\",\n",
    "            history=AIHistoryOptions(assistant_history_type=\"text\"),\n",
    "        ),\n",
    "        storage=storage,\n",
    "    )\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
