{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, you will learn to add AI options to a basic Teams-ai bot.\n",
    "\n",
    "A Teams-ai application object can have an `ApplicationOptions.ai` property with `AIOption` type. A bot application with `ApplicationOptions.ai` property can work as a bot with AI abilities. For example, it can give a artificial response to your input according to prompts.\n",
    "\n",
    "`AIOptions` consists of `planner`, `prompt` and `history`. The `prompt` determines what prompts to use. The `planner` will generate plan according to given prompts and chat history. We will show you how `prompt` and  `planner` work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt\n",
    "In this section, we will introduce how to generate a prompts folder as a prompts source base, which can be loaded by the `AIOption`.\n",
    "\n",
    "Here is a sample code snippet about how to generate prompts source folder `src/prompts`, and a named prompt folder `src/prompts/chat` which consists of `config.json` and `skprompt.txt` as a `\"chat\"` prompt. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Define the file paths\n",
    "prompts_folder_path = \"src/prompts/\"\n",
    "prompt_name = \"chat/\"\n",
    "config_file_path = f\"{prompts_folder_path}{prompt_name}config.json\"\n",
    "skprompt_file_path = f\"{prompts_folder_path}{prompt_name}skprompt.txt\"\n",
    "if not os.path.exists(prompts_folder_path):\n",
    "    os.makedirs(prompts_folder_path)\n",
    "if not os.path.exists(f\"{prompts_folder_path}{prompt_name}\"):\n",
    "    os.makedirs(f\"{prompts_folder_path}{prompt_name}\")\n",
    "\n",
    "# Define the config_json and skprompt_txt\n",
    "config_json = \"\"\"{\n",
    "    \"schema\": 1,\n",
    "    \"description\": \"Chat with Teams Chef\",\n",
    "    \"type\": \"completion\",\n",
    "    \"completion\": {\n",
    "      \"max_tokens\": 150,\n",
    "      \"temperature\": 0.9,\n",
    "      \"top_p\": 0.0,\n",
    "      \"presence_penalty\": 0.6,\n",
    "      \"frequency_penalty\": 0.0,\n",
    "      \"stop_sequences\": [\n",
    "        \"Human:\",\n",
    "        \"AI:\"\n",
    "      ]\n",
    "    }\n",
    "}\"\"\"\n",
    "\n",
    "skprompt_txt = \"\"\"The following is a conversation with an AI assistant, its name is Teams Chef. \n",
    "Teams Chef is an expert in Microsoft Teams apps development and the Human is junior developer learning Microsoft Teams development for the first time. \n",
    "Teams Chef should always reply by explaining new concepts in simple terms using cooking as parallel concepts. \n",
    "Teams Chef should always greet the human, ask them their name, and then guide the junior developer in his journey to build new apps for Microsoft Teams.\n",
    "\n",
    "{{$history}}\n",
    "Human: {{$input}}\n",
    "TeamsChef:\"\"\"\n",
    "\n",
    "# Write the config_json to config.json file\n",
    "with open(config_file_path, \"w\") as config_file:\n",
    "    config_file.write(config_json)\n",
    "\n",
    "# Write the skprompt_txt to skprompt.txt file\n",
    "with open(skprompt_file_path, \"w\") as skprompt_file:\n",
    "    skprompt_file.write(skprompt_txt)\n",
    "\n",
    "# Print a success message\n",
    "print(f\"Files written successfully. Please check the files in the following paths:\\n{config_file_path}\\n{skprompt_file_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Planner\n",
    "In this section, we will introduce how does a `planner` generates a plan."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. First, we import needed packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules from src\n",
    "import src.config as config\n",
    "from src.bot import *\n",
    "from teams import AIHistoryOptions, AzureOpenAIPlanner, AzureOpenAIPlannerOptions, ConversationHistory, ConversationState, TempState, UserState\n",
    "from botbuilder.schema import ChannelAccount, ConversationAccount\n",
    "from unittest.mock import MagicMock "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Second, we initiate a `planner` object with Azure OpenAI keys and values, determining prompt folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# register a planner\n",
    "config.AZURE_OPENAI_KEY = 'b9e28116eeff4b129db5155fd261a541' # Azure OpenAI API key\n",
    "config.AZURE_OPENAI_MODEL_DEPLOYMENT_NAME = 'gpt-35-turbo-zihch' # Azure OpenAI model deployment name\n",
    "config.AZURE_OPENAI_ENDPOINT = 'https://azure-openai-zihch.openai.azure.com/' # Azure OpenAI endpoint\n",
    "planner = AzureOpenAIPlanner(\n",
    "    AzureOpenAIPlannerOptions(\n",
    "        config.AZURE_OPENAI_KEY,\n",
    "        config.AZURE_OPENAI_MODEL_DEPLOYMENT_NAME,\n",
    "        config.AZURE_OPENAI_ENDPOINT,\n",
    "        prompt_folder=\"src/prompts\",\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Then, we mock a `TurnContext` object and a `TurnState` object. They will be used when generating a plan.\n",
    "\n",
    "    > In this example, we set `TempState.input='hi'` to emulate that user inputs 'hi' as the input text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# mock the TurnContext object\n",
    "context=MagicMock(spec=TurnContext)\n",
    "\n",
    "# mock the TurnState object\n",
    "temp=TempState(input='hi', history='', output='')\n",
    "user=UserState(__key__='mock_key', channel=ChannelAccount())\n",
    "conversation=ConversationState(\n",
    "    __key__='mock_key',\n",
    "    account=ConversationAccount(),\n",
    "    channel=ChannelAccount(),\n",
    "    history=ConversationHistory()\n",
    ")\n",
    "state=TurnState(\n",
    "    temp=temp,\n",
    "    user=user,\n",
    "    conversation=conversation\n",
    ")\n",
    "\n",
    "print(f\"context={context}\")\n",
    "print(f\"state={state}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Last, we call `planner._prompt_manager.render_prompt()` and `planner.generate_plan()` to see what prompt content passed to planner and what plan is generated by planner. \n",
    "\n",
    "    > In this example, we choose `\"chat\"` as the prompt template name to generate a prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# render prompt\n",
    "prompt=\"chat\"\n",
    "prompt_templates = await planner._prompt_manager.render_prompt(context, state, prompt)\n",
    "print(f\"prompt_templates:\\n{prompt_templates}\")\n",
    "\n",
    "# generate plan\n",
    "plan = await planner.generate_plan(\n",
    "    context, state, prompt, history_options=AIHistoryOptions(assistant_history_type=\"text\")\n",
    ")\n",
    "print(f\"plan:\\n{plan}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add AIOptions to a bot\n",
    "Now we know how to manage the prompts folder and how to set up a planner. We can initiate a Teams-ai bot application with `AIOptions` with `prompt` and `planner` we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from botbuilder.core import BotFrameworkAdapterSettings, MemoryStorage\n",
    "from teams import AIOptions, Application, ApplicationOptions, TurnState\n",
    "storage = MemoryStorage()\n",
    "app = Application[TurnState](\n",
    "    ApplicationOptions(\n",
    "        auth=BotFrameworkAdapterSettings(\n",
    "            app_id=config.app_id,\n",
    "            app_password=config.app_password,\n",
    "        ),\n",
    "        ai=AIOptions(\n",
    "            planner=planner,\n",
    "            prompt=\"chat\",\n",
    "            history=AIHistoryOptions(assistant_history_type=\"text\"),\n",
    "        ),\n",
    "        storage=storage,\n",
    "    )\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
