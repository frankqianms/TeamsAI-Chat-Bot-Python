{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, you will learn to add AI options to a basic Teams-ai bot.\n",
    "\n",
    "A Teams-ai application object can have an `ApplicationOptions.ai` property with `AIOption` type. A bot application with `ApplicationOptions.ai` property can work as a bot with AI abilities. For example, it can give a artificial response to your input according to prompts.\n",
    "\n",
    "`AIOptions` consists of `planner`, `prompt` and `history`. The `prompt` determines what prompts to use. The `planner` will generate plan according to given prompts and chat history. We will show you how `prompt` and  `planner` work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt\n",
    "In most cases, you'll want to create your prompts in a separate file so you can easily import them into Teams-ai across multiple projects and share them with others. \n",
    "\n",
    "In this section, we'll demonstrate how to create the files necessary for a prompt so you can easily use them in `AIOption`.\n",
    "\n",
    "Here is a sample code snippet about how to generate a prompts home folder `src/prompts`, and a named prompt folder `src/prompts/chat`. In this example, the prompt will be called `'chat'`. Once inside of a prompts folder, you'll need to create two new files `config.json` and `skprompt.txt`. The `skprompt.txt` file contains the prompt that will be sent to the AI service and the `config.json` file contains the configuration along with semantic descriptions that can be used by planners.\n",
    "```\n",
    "Prompts\n",
    "│\n",
    "└─── chat\n",
    "     |\n",
    "     └─── config.json\n",
    "     └─── skprompt.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> We have already prepare the files in [src/prompts/chat](./src/prompts/chat/). In a real scenario, you would need to manually manage the prompts folder following the file naming conventions. Please refer [semantic kernel doc](https://learn.microsoft.com/en-us/semantic-kernel/prompts/saving-prompts-as-files?tabs=python) for more information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt actions\n",
    "\n",
    "Plans let the model perform actions or respond to the user. You can create a schema of the plan and add a list of actions that you support to perform an action and pass arguments. The OpenAI endpoint figures out the actions required to be used, extracts all the entities, and passes those as arguments to the action call. A Teams-ai application with `AIOptions` will always generate a plan with either `\"SAY\"` type commands or `\"DO\"` type commands. \n",
    "* `SAY`: `SAY` commands will give a response text by calling OpenAI according to user's input.\n",
    "* `DO`: `DO` commands will map action names with entities and call action methods. We use annotation like `@app.ai.action(\"<action_name>\")` to hook up methods with action names.\n",
    "\n",
    "The language supports features that allow you to include variables, call external functions, and pass parameters to functions. You don't need to write any code or import any external libraries, just use the curly braces {{...}} to embed expressions in your prompts.\n",
    "* `{{function}}`: Calls a registered function and inserts its return value string. We use annotation like `@app.ai.function(\"<function_name>\")` to hook up methods with function names.\n",
    "* `{{$input}}`: Inserts the message text. It gets its value from state.temp.input.\n",
    "* `{{$history}}`: Inserts the history. It gets its value from state.temp.history.\n",
    "\n",
    "> For more information of prompt syntax in Teams-ai, please refer to [this doc](https://learn.microsoft.com/en-us/microsoftteams/platform/bots/how-to/teams%20conversational%20ai/how-conversation-ai-get-started?tabs=javascript4%2Cjavascript1%2Cjavascript3%2Cjavascript2#prompt).\n",
    "\n",
    "> The following text content shows a prompt template that defines some lights operating actions. We will introduce how the prompt with different `DO` and `SAY` commands work in the \"Add AIOptions to a bot\" [section](#add-aioptions-to-a-bot)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skprompt_txt=\"\"\"The following is a conversation with an AI assistant. \n",
    "The assistant can turn a light on or off.\n",
    "The assistant must return the following JSON structure:\n",
    "\n",
    "{\"type\":\"plan\",\"commands\":[{\"type\":\"DO\",\"action\":\"<name>\",\"entities\":{\"<name>\":<value>}},{\"type\":\"SAY\",\"response\":\"<response>\"}]}\n",
    "\n",
    "The following actions are supported:\n",
    "\n",
    "- LightsOn\n",
    "- LightsOff\n",
    "\n",
    "Always respond in the form of a JSON based plan. Stick with DO/SAY.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Planner\n",
    "In this section, we will introduce how does a `planner` generates a plan."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. First, we import needed packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules from src\n",
    "import src.config as config\n",
    "from src.bot import *\n",
    "from teams import AIHistoryOptions, AzureOpenAIPlanner, AzureOpenAIPlannerOptions, ConversationHistory, ConversationState, TempState, UserState\n",
    "from botbuilder.schema import ChannelAccount, ConversationAccount\n",
    "from unittest.mock import MagicMock "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Second, we initiate a `planner` object with Azure OpenAI keys and values, determining prompt home folder.\n",
    "\n",
    "    > Please config your **AZURE_OPENAI_KEY**, **AZURE_OPENAI_MODEL_DEPLOYMENT_NAME** and **AZURE_OPENAI_ENDPOINT** in `.env` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# register a planner\n",
    "planner = AzureOpenAIPlanner(\n",
    "    AzureOpenAIPlannerOptions(\n",
    "        config.AZURE_OPENAI_KEY,\n",
    "        config.AZURE_OPENAI_MODEL_DEPLOYMENT_NAME,\n",
    "        config.AZURE_OPENAI_ENDPOINT,\n",
    "        prompt_folder=\"src/prompts\",\n",
    "    )\n",
    ")\n",
    "print(f\"AZURE_OPENAI_KEY={config.AZURE_OPENAI_KEY}\")\n",
    "print(f\"AZURE_OPENAI_MODEL_DEPLOYMENT_NAME={config.AZURE_OPENAI_MODEL_DEPLOYMENT_NAME}\")\n",
    "print(f\"AZURE_OPENAI_ENDPOINT={config.AZURE_OPENAI_ENDPOINT}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Then, we mock a `TurnContext` object and a `TurnState` object. They will be used when generating a plan. We already defined them in [src/utils/mockConstants.py](src/utils/mockConstants.py).\n",
    "\n",
    "    > In this example, we set `TempState.input='hi'` to emulate that user inputs 'hi' as the input text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.mockConstants import *\n",
    "\n",
    "print(f\"context={context}\")\n",
    "print(f\"state.temp={state.temp}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Last, we call `planner._prompt_manager.render_prompt()` and `planner.generate_plan()` to see what prompt content passed to planner and what plan is generated by planner. \n",
    "\n",
    "    > In this example, we choose `\"chat\"` as the prompt template name to generate a prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# render prompt\n",
    "prompt_name=\"chat\"\n",
    "prompt = await planner._prompt_manager.render_prompt(context, state, prompt_name)\n",
    "print(f\"prompt:\\n{prompt.text}\\n\")\n",
    "\n",
    "# generate plan\n",
    "plan = await planner.generate_plan(\n",
    "    context, state, prompt_name, history_options=AIHistoryOptions(assistant_history_type=\"text\")\n",
    ")\n",
    "print(f\"plan:\\n{plan}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add AIOptions to a bot\n",
    "Now we know how to manage the prompts folder and how to set up a planner. We can initiate a Teams-ai bot application with `AIOptions` with `prompt` and `planner` we need. We will show you how does an application with \"chatLight\" as prompt in AIOptions work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we generate a prompt template named \"chatLight\" with `DO` and `SAY` commands.\n",
    "\n",
    "> We have already prepare the files in [src/prompts/chatLight](./src/prompts/chatLight/), and the following code will copy them into `src/prompts/`. In a real scenario, you would need to manually manage the prompts folder following the file naming conventions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we create an Application with `prompt=\"chatLight\"` in `AIOptions`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from botbuilder.core import BotFrameworkAdapterSettings, MemoryStorage\n",
    "from teams import AIOptions, Application, ApplicationOptions, TurnState\n",
    "storage = MemoryStorage()\n",
    "app = Application[TurnState](\n",
    "    ApplicationOptions(\n",
    "        auth=BotFrameworkAdapterSettings(\n",
    "            app_id=config.app_id,\n",
    "            app_password=config.app_password,\n",
    "        ),\n",
    "        ai=AIOptions(\n",
    "            planner=planner,\n",
    "            prompt=\"chatLight\",\n",
    "            history=AIHistoryOptions(assistant_history_type=\"text\"),\n",
    "        ),\n",
    "        storage=storage,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we need to define actions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MyActionTurnContext = ActionTurnContext[Dict[str, Any]]\n",
    "\n",
    "@app.ai.action(\"LightsOn\")\n",
    "async def on_lights_on(context, state):\n",
    "    print(\"[lights on]\")\n",
    "    return True\n",
    "\n",
    "\n",
    "@app.ai.action(\"LightsOff\")\n",
    "async def on_lights_off(context, state):\n",
    "    print(\"[lights off]\")\n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start the bot using `Flask` server. After starting the server, you can try it with [Teams App Test Tool](https://learn.microsoft.com/en-us/microsoftteams/platform/toolkit/debug-your-teams-app-test-tool). You only need to run 2 commands if you have installed `Node` in your system.\n",
    "```bash\n",
    "npm install -g @microsoft/teams-app-test-tool\n",
    "teamsapptester start\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, request, jsonify\n",
    "from botbuilder.schema import Activity\n",
    "\n",
    "# Define the Flask API\n",
    "api = Flask(__name__)\n",
    "# Define the route for receiving messages\n",
    "@api.route('/api/messages', methods=['POST'])\n",
    "async def on_messages():\n",
    "    activity = Activity().deserialize(request.json)\n",
    "\n",
    "    auth_header = request.headers['Authorization'] if 'Authorization' in request.headers else ''\n",
    "    response = await app.process_activity(activity, auth_header)\n",
    "    \n",
    "    if response:\n",
    "        return jsonify(response.body), response.status\n",
    "    return '', 200\n",
    "\n",
    "# Run the Flask API\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        api.run(host='localhost', port=config.port)\n",
    "    except Exception as error:\n",
    "        raise error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you successfully install Teams App Test Tool and start it in a browser, you will see the test window. Now you can test your echo bot!\n",
    "![Alt text](src/utils/image.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
